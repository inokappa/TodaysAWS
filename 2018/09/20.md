# 2018/09/20 今日の AWS

## 今日の AWS ~ AWS Certified Solutions Architect – Professional Level のサンプル問題に挑む ~

公開されている[サンプル試験問題](https://d1.awsstatic.com/Train%20&%20Cert/docs/AWS_certified_solutions_architect_professional_examsample.pdf)を解く. なぜ, その答えになるのかをちゃんと理解する必要がある.

### Q6. Storage Gateway

#### 設問

* 900GB のデータを中央ファイルサーバー経由で共有する, 社内のレガシーエンジニアリングアプリケーションをホストしている
* エンジニアリングデータは, メガバイトから数ギガバイトまでのサイズのファイルが数千ある
* エンジニアは通常, 1日に 5〜10％ のファイルを修正する
* CTO はこのアプリケーションをAWSに移行したいが, 週末にアプリケーションを移行してユーザのダウンタイムを最小限に抑えることができる場合に限る
* 既存の 45Mbps インターネット接続を使用して 900GB のデータを転送するには, 最低48時間かかる

AWS でアプリケーションの環境を複製した後, どのオプションを使用すれば, アプリケーションのデータをAWSに移行できるか.

#### 選択肢

A) Copy the data to Amazon S3 using multiple threads and multi-part upload for large files over the weekend, and work in parallel with your developers to reconfigure the replicated application environment to leverage Amazon S3 to serve the engineering files.

* 複数のスレッドを使用して Amazon S3 にデータをコピーし, 週末に大容量ファイルのマルチパートアップロードを行う
* 開発者と連携して複製されたアプリケーション環境を再構成して Amazon S3 を利用してエンジニアリングファイルを提供する

B) Sync the application data to Amazon S3 starting a week before the migration, on Friday morning perform a final sync, and copy the entire data set to your AWS file server after the sync completes.

* マイグレーションの 1 週間前から, アマゾン S3 にアプリケーションデータを同期させる
* 金曜日の午前には最終同期を実行し, 同期が完了したらデータセット全体を AWS ファイルサーバーにコピーする

C) Copy the application data to a 1-TB USB drive on Friday and immediately send overnight, with Saturday delivery, the USB drive to AWS Import/Export to be imported as an EBS volume, mount the resulting EBS volume to your AWS file server on Sunday.

* アプリケーションデータを金曜日に 1TB の USB ドライブにコピーし
* すぐに土曜日の配送で一晩送って, USB ドライブを AWS インポート/エクスポートに EBS ボリュームとしてインポート
* 日曜日に結果の EBS ボリュームを AWS ファイルサーバーにマウントする

D) Leverage the AWS Storage Gateway to create a Gateway-Stored volume. On Friday copy the application data to the Storage Gateway volume. After the data has been copied, perform a snapshot of the volume and restore the volume as an EBS volume to be attached to your AWS file server on Sunday.

* AWS Storage Gateway を活用してゲートウェイ格納ボリュームを作成
* 金曜日にアプリケーションデータを Storage Gateway ボリュームにコピーする
* データのコピー後, 日曜日にボリュームのスナップショットを実行して, AWS ファイルサーバーに接続する EBS ボリュームとしてボリュームを復元する

#### 解答

* B だと思う

一週間前からデータ同期やってるいるので, ひとまず全データは S3 にコピーは完了するし, S3 と AWS ファイルサーバー間であれば転送時間は短縮できるような気がする...

#### なぜ, その答えなん？

* A) だと週末だけでファイルを転送出来ない可能性がある (転送に最低でも 48 時間かかるというので...)
* C) 1TB の USB ドライブにコピーする時間, 配送する時間, AWS インポート, エクスポートする時間等不確定要素が多すぎるので俺なら選択しない
* D) Gateway Stored Volumes だと要件を満たさない, 設問の場合だと Gateway-Cached Volumes を選ぶべき

#### Storage Gateway について

* [AWS Black Belt Techシリーズ AWS Storage Gateway](https://www.slideshare.net/AmazonWebServicesJapan/aws-black-belt-tech-aws-storage-gateway)
    * Gateway-Stored Volumes
        * オンプレミス上のデータをスナップショットとして S3 に取得する
        * DR 目的
    * Gateway-Cached Volumes
        * S3 を直接利用するストレージ (ファイルシステムとして利用)
        * アクセス頻度の高いデータはキャッシュとしてローカルに保持
    * Gateway-VTL
        * 仮想テープライブラリ
        * S3 と Glacier に格納する
